{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd =  pd.read_csv(\"train_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>rsi</th>\n",
       "      <th>ema_fast</th>\n",
       "      <th>ema_slow</th>\n",
       "      <th>volatility</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>2000-10-16</td>\n",
       "      <td>0.58820</td>\n",
       "      <td>0.59230</td>\n",
       "      <td>0.57750</td>\n",
       "      <td>0.57850</td>\n",
       "      <td>30.382367</td>\n",
       "      <td>0.602323</td>\n",
       "      <td>0.610376</td>\n",
       "      <td>2.605170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>2000-10-23</td>\n",
       "      <td>0.57860</td>\n",
       "      <td>0.58760</td>\n",
       "      <td>0.57310</td>\n",
       "      <td>0.57840</td>\n",
       "      <td>30.343134</td>\n",
       "      <td>0.599133</td>\n",
       "      <td>0.608889</td>\n",
       "      <td>2.598570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>2000-10-30</td>\n",
       "      <td>0.57830</td>\n",
       "      <td>0.60440</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.59800</td>\n",
       "      <td>45.262621</td>\n",
       "      <td>0.598982</td>\n",
       "      <td>0.608382</td>\n",
       "      <td>2.659958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>2000-11-06</td>\n",
       "      <td>0.59820</td>\n",
       "      <td>0.60790</td>\n",
       "      <td>0.59400</td>\n",
       "      <td>0.60400</td>\n",
       "      <td>48.872746</td>\n",
       "      <td>0.599651</td>\n",
       "      <td>0.608179</td>\n",
       "      <td>2.609805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>2000-11-13</td>\n",
       "      <td>0.60420</td>\n",
       "      <td>0.60520</td>\n",
       "      <td>0.59410</td>\n",
       "      <td>0.59660</td>\n",
       "      <td>44.936330</td>\n",
       "      <td>0.599244</td>\n",
       "      <td>0.607640</td>\n",
       "      <td>2.586345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1030</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>0.89002</td>\n",
       "      <td>0.89365</td>\n",
       "      <td>0.88333</td>\n",
       "      <td>0.88779</td>\n",
       "      <td>47.151897</td>\n",
       "      <td>0.895761</td>\n",
       "      <td>0.889108</td>\n",
       "      <td>1.564625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1031</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>0.89050</td>\n",
       "      <td>0.90183</td>\n",
       "      <td>0.86835</td>\n",
       "      <td>0.86835</td>\n",
       "      <td>37.551961</td>\n",
       "      <td>0.892106</td>\n",
       "      <td>0.888143</td>\n",
       "      <td>1.760791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1032</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.87443</td>\n",
       "      <td>0.88081</td>\n",
       "      <td>0.85808</td>\n",
       "      <td>0.86451</td>\n",
       "      <td>35.993098</td>\n",
       "      <td>0.888426</td>\n",
       "      <td>0.887044</td>\n",
       "      <td>1.830085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>1033</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.86453</td>\n",
       "      <td>0.86687</td>\n",
       "      <td>0.85770</td>\n",
       "      <td>0.86380</td>\n",
       "      <td>35.698024</td>\n",
       "      <td>0.885143</td>\n",
       "      <td>0.885962</td>\n",
       "      <td>1.776589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1034</td>\n",
       "      <td>2019-10-28</td>\n",
       "      <td>0.86390</td>\n",
       "      <td>0.86520</td>\n",
       "      <td>0.85958</td>\n",
       "      <td>0.86280</td>\n",
       "      <td>35.259578</td>\n",
       "      <td>0.882164</td>\n",
       "      <td>0.884885</td>\n",
       "      <td>1.698128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        Date     Open     High      Low    Close        rsi  \\\n",
       "0            41  2000-10-16  0.58820  0.59230  0.57750  0.57850  30.382367   \n",
       "1            42  2000-10-23  0.57860  0.58760  0.57310  0.57840  30.343134   \n",
       "2            43  2000-10-30  0.57830  0.60440  0.57710  0.59800  45.262621   \n",
       "3            44  2000-11-06  0.59820  0.60790  0.59400  0.60400  48.872746   \n",
       "4            45  2000-11-13  0.60420  0.60520  0.59410  0.59660  44.936330   \n",
       "..          ...         ...      ...      ...      ...      ...        ...   \n",
       "987        1030  2019-09-30  0.89002  0.89365  0.88333  0.88779  47.151897   \n",
       "988        1031  2019-10-07  0.89050  0.90183  0.86835  0.86835  37.551961   \n",
       "989        1032  2019-10-14  0.87443  0.88081  0.85808  0.86451  35.993098   \n",
       "990        1033  2019-10-21  0.86453  0.86687  0.85770  0.86380  35.698024   \n",
       "991        1034  2019-10-28  0.86390  0.86520  0.85958  0.86280  35.259578   \n",
       "\n",
       "     ema_fast  ema_slow  volatility  target  \n",
       "0    0.602323  0.610376    2.605170       1  \n",
       "1    0.599133  0.608889    2.598570       1  \n",
       "2    0.598982  0.608382    2.659958       1  \n",
       "3    0.599651  0.608179    2.609805       1  \n",
       "4    0.599244  0.607640    2.586345       1  \n",
       "..        ...       ...         ...     ...  \n",
       "987  0.895761  0.889108    1.564625       0  \n",
       "988  0.892106  0.888143    1.760791       0  \n",
       "989  0.888426  0.887044    1.830085       0  \n",
       "990  0.885143  0.885962    1.776589       0  \n",
       "991  0.882164  0.884885    1.698128       0  \n",
       "\n",
       "[992 rows x 11 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>rsi</th>\n",
       "      <th>ema_fast</th>\n",
       "      <th>ema_slow</th>\n",
       "      <th>volatility</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>730409</td>\n",
       "      <td>0.58820</td>\n",
       "      <td>0.59230</td>\n",
       "      <td>0.57750</td>\n",
       "      <td>0.57850</td>\n",
       "      <td>30.382367</td>\n",
       "      <td>0.602323</td>\n",
       "      <td>0.610376</td>\n",
       "      <td>2.605170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>730416</td>\n",
       "      <td>0.57860</td>\n",
       "      <td>0.58760</td>\n",
       "      <td>0.57310</td>\n",
       "      <td>0.57840</td>\n",
       "      <td>30.343134</td>\n",
       "      <td>0.599133</td>\n",
       "      <td>0.608889</td>\n",
       "      <td>2.598570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>730423</td>\n",
       "      <td>0.57830</td>\n",
       "      <td>0.60440</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.59800</td>\n",
       "      <td>45.262621</td>\n",
       "      <td>0.598982</td>\n",
       "      <td>0.608382</td>\n",
       "      <td>2.659958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>730430</td>\n",
       "      <td>0.59820</td>\n",
       "      <td>0.60790</td>\n",
       "      <td>0.59400</td>\n",
       "      <td>0.60400</td>\n",
       "      <td>48.872746</td>\n",
       "      <td>0.599651</td>\n",
       "      <td>0.608179</td>\n",
       "      <td>2.609805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>730437</td>\n",
       "      <td>0.60420</td>\n",
       "      <td>0.60520</td>\n",
       "      <td>0.59410</td>\n",
       "      <td>0.59660</td>\n",
       "      <td>44.936330</td>\n",
       "      <td>0.599244</td>\n",
       "      <td>0.607640</td>\n",
       "      <td>2.586345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1030</td>\n",
       "      <td>737332</td>\n",
       "      <td>0.89002</td>\n",
       "      <td>0.89365</td>\n",
       "      <td>0.88333</td>\n",
       "      <td>0.88779</td>\n",
       "      <td>47.151897</td>\n",
       "      <td>0.895761</td>\n",
       "      <td>0.889108</td>\n",
       "      <td>1.564625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1031</td>\n",
       "      <td>737339</td>\n",
       "      <td>0.89050</td>\n",
       "      <td>0.90183</td>\n",
       "      <td>0.86835</td>\n",
       "      <td>0.86835</td>\n",
       "      <td>37.551961</td>\n",
       "      <td>0.892106</td>\n",
       "      <td>0.888143</td>\n",
       "      <td>1.760791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1032</td>\n",
       "      <td>737346</td>\n",
       "      <td>0.87443</td>\n",
       "      <td>0.88081</td>\n",
       "      <td>0.85808</td>\n",
       "      <td>0.86451</td>\n",
       "      <td>35.993098</td>\n",
       "      <td>0.888426</td>\n",
       "      <td>0.887044</td>\n",
       "      <td>1.830085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>1033</td>\n",
       "      <td>737353</td>\n",
       "      <td>0.86453</td>\n",
       "      <td>0.86687</td>\n",
       "      <td>0.85770</td>\n",
       "      <td>0.86380</td>\n",
       "      <td>35.698024</td>\n",
       "      <td>0.885143</td>\n",
       "      <td>0.885962</td>\n",
       "      <td>1.776589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1034</td>\n",
       "      <td>737360</td>\n",
       "      <td>0.86390</td>\n",
       "      <td>0.86520</td>\n",
       "      <td>0.85958</td>\n",
       "      <td>0.86280</td>\n",
       "      <td>35.259578</td>\n",
       "      <td>0.882164</td>\n",
       "      <td>0.884885</td>\n",
       "      <td>1.698128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    Date     Open     High      Low    Close        rsi  \\\n",
       "0            41  730409  0.58820  0.59230  0.57750  0.57850  30.382367   \n",
       "1            42  730416  0.57860  0.58760  0.57310  0.57840  30.343134   \n",
       "2            43  730423  0.57830  0.60440  0.57710  0.59800  45.262621   \n",
       "3            44  730430  0.59820  0.60790  0.59400  0.60400  48.872746   \n",
       "4            45  730437  0.60420  0.60520  0.59410  0.59660  44.936330   \n",
       "..          ...     ...      ...      ...      ...      ...        ...   \n",
       "987        1030  737332  0.89002  0.89365  0.88333  0.88779  47.151897   \n",
       "988        1031  737339  0.89050  0.90183  0.86835  0.86835  37.551961   \n",
       "989        1032  737346  0.87443  0.88081  0.85808  0.86451  35.993098   \n",
       "990        1033  737353  0.86453  0.86687  0.85770  0.86380  35.698024   \n",
       "991        1034  737360  0.86390  0.86520  0.85958  0.86280  35.259578   \n",
       "\n",
       "     ema_fast  ema_slow  volatility  target  \n",
       "0    0.602323  0.610376    2.605170       1  \n",
       "1    0.599133  0.608889    2.598570       1  \n",
       "2    0.598982  0.608382    2.659958       1  \n",
       "3    0.599651  0.608179    2.609805       1  \n",
       "4    0.599244  0.607640    2.586345       1  \n",
       "..        ...       ...         ...     ...  \n",
       "987  0.895761  0.889108    1.564625       0  \n",
       "988  0.892106  0.888143    1.760791       0  \n",
       "989  0.888426  0.887044    1.830085       0  \n",
       "990  0.885143  0.885962    1.776589       0  \n",
       "991  0.882164  0.884885    1.698128       0  \n",
       "\n",
       "[992 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datetime format\n",
    "dd['Date']= pd.to_datetime(dd['Date'])\n",
    "dd['Date']=dd['Date'].map(dt.datetime.toordinal)\n",
    "dd\n",
    "#How do the outliers affect the volatility? Is it relevant for the network? --- What variables have no outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop first column of dataframe - MAYBE NOT. MAYBE IT HELPS LEARN THE ORDER? OR IS IT AUTOMATIC ---???\n",
    "dd = dd.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining not numeric variables\n",
    "not_numeric_variables = ['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>rsi</th>\n",
       "      <th>ema_fast</th>\n",
       "      <th>ema_slow</th>\n",
       "      <th>volatility</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730409</td>\n",
       "      <td>-1.925794</td>\n",
       "      <td>-1.761427</td>\n",
       "      <td>-1.997663</td>\n",
       "      <td>-2.032259</td>\n",
       "      <td>-2.049713</td>\n",
       "      <td>-1.778835</td>\n",
       "      <td>-1.683272</td>\n",
       "      <td>0.319710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>730416</td>\n",
       "      <td>-2.025880</td>\n",
       "      <td>-1.805167</td>\n",
       "      <td>-2.044207</td>\n",
       "      <td>-2.033303</td>\n",
       "      <td>-2.053536</td>\n",
       "      <td>-1.812372</td>\n",
       "      <td>-1.699184</td>\n",
       "      <td>0.315252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730423</td>\n",
       "      <td>-2.029008</td>\n",
       "      <td>-1.648818</td>\n",
       "      <td>-2.001894</td>\n",
       "      <td>-1.828827</td>\n",
       "      <td>-0.599775</td>\n",
       "      <td>-1.813960</td>\n",
       "      <td>-1.704603</td>\n",
       "      <td>0.356716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>730430</td>\n",
       "      <td>-1.821538</td>\n",
       "      <td>-1.616245</td>\n",
       "      <td>-1.823124</td>\n",
       "      <td>-1.766232</td>\n",
       "      <td>-0.248003</td>\n",
       "      <td>-1.806926</td>\n",
       "      <td>-1.706784</td>\n",
       "      <td>0.322840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>730437</td>\n",
       "      <td>-1.758984</td>\n",
       "      <td>-1.641373</td>\n",
       "      <td>-1.822067</td>\n",
       "      <td>-1.843432</td>\n",
       "      <td>-0.631569</td>\n",
       "      <td>-1.811203</td>\n",
       "      <td>-1.712545</td>\n",
       "      <td>0.306994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>737332</td>\n",
       "      <td>1.220870</td>\n",
       "      <td>1.043083</td>\n",
       "      <td>1.237436</td>\n",
       "      <td>1.194386</td>\n",
       "      <td>-0.415684</td>\n",
       "      <td>1.306336</td>\n",
       "      <td>1.298820</td>\n",
       "      <td>-0.383131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>737339</td>\n",
       "      <td>1.225875</td>\n",
       "      <td>1.119210</td>\n",
       "      <td>1.078976</td>\n",
       "      <td>0.991580</td>\n",
       "      <td>-1.351105</td>\n",
       "      <td>1.267910</td>\n",
       "      <td>1.288490</td>\n",
       "      <td>-0.250630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>737346</td>\n",
       "      <td>1.058335</td>\n",
       "      <td>0.923588</td>\n",
       "      <td>0.970339</td>\n",
       "      <td>0.951519</td>\n",
       "      <td>-1.503001</td>\n",
       "      <td>1.229225</td>\n",
       "      <td>1.276730</td>\n",
       "      <td>-0.203825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>737353</td>\n",
       "      <td>0.955121</td>\n",
       "      <td>0.793856</td>\n",
       "      <td>0.966319</td>\n",
       "      <td>0.944112</td>\n",
       "      <td>-1.531753</td>\n",
       "      <td>1.194702</td>\n",
       "      <td>1.265164</td>\n",
       "      <td>-0.239959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>737360</td>\n",
       "      <td>0.948553</td>\n",
       "      <td>0.778314</td>\n",
       "      <td>0.986206</td>\n",
       "      <td>0.933680</td>\n",
       "      <td>-1.574476</td>\n",
       "      <td>1.163380</td>\n",
       "      <td>1.253638</td>\n",
       "      <td>-0.292955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Open      High       Low     Close       rsi  ema_fast  \\\n",
       "0    730409 -1.925794 -1.761427 -1.997663 -2.032259 -2.049713 -1.778835   \n",
       "1    730416 -2.025880 -1.805167 -2.044207 -2.033303 -2.053536 -1.812372   \n",
       "2    730423 -2.029008 -1.648818 -2.001894 -1.828827 -0.599775 -1.813960   \n",
       "3    730430 -1.821538 -1.616245 -1.823124 -1.766232 -0.248003 -1.806926   \n",
       "4    730437 -1.758984 -1.641373 -1.822067 -1.843432 -0.631569 -1.811203   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "987  737332  1.220870  1.043083  1.237436  1.194386 -0.415684  1.306336   \n",
       "988  737339  1.225875  1.119210  1.078976  0.991580 -1.351105  1.267910   \n",
       "989  737346  1.058335  0.923588  0.970339  0.951519 -1.503001  1.229225   \n",
       "990  737353  0.955121  0.793856  0.966319  0.944112 -1.531753  1.194702   \n",
       "991  737360  0.948553  0.778314  0.986206  0.933680 -1.574476  1.163380   \n",
       "\n",
       "     ema_slow  volatility  target  \n",
       "0   -1.683272    0.319710       1  \n",
       "1   -1.699184    0.315252       1  \n",
       "2   -1.704603    0.356716       1  \n",
       "3   -1.706784    0.322840       1  \n",
       "4   -1.712545    0.306994       1  \n",
       "..        ...         ...     ...  \n",
       "987  1.298820   -0.383131       0  \n",
       "988  1.288490   -0.250630       0  \n",
       "989  1.276730   -0.203825       0  \n",
       "990  1.265164   -0.239959       0  \n",
       "991  1.253638   -0.292955       0  \n",
       "\n",
       "[992 rows x 10 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling numeric variables\n",
    "numeric_cols = dd.drop(not_numeric_variables, axis=1).columns\n",
    "\n",
    "y = dd.iloc[:,dd.shape[1]-1:dd.shape[1]] #Not scale the target variable\n",
    "\n",
    "dd_scaled = dd.copy()\n",
    "dd_scaled[numeric_cols]=(dd_scaled[numeric_cols]-dd_scaled[numeric_cols].mean())/dd_scaled[numeric_cols].std()\n",
    "dd_scaled = dd_scaled.drop(y.columns, axis = 1)\n",
    "dd_scaled = pd.concat([dd_scaled, y], axis=1)\n",
    "dd_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70% Train, 30% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_train = dd.sample(frac=0.7,random_state=123)\n",
    "dd_val = dd.drop(dd_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>rsi</th>\n",
       "      <th>ema_fast</th>\n",
       "      <th>ema_slow</th>\n",
       "      <th>volatility</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>735645</td>\n",
       "      <td>0.73990</td>\n",
       "      <td>0.74426</td>\n",
       "      <td>0.73400</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>26.837951</td>\n",
       "      <td>0.762767</td>\n",
       "      <td>0.785421</td>\n",
       "      <td>1.684036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>734147</td>\n",
       "      <td>0.82953</td>\n",
       "      <td>0.84943</td>\n",
       "      <td>0.82856</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>46.154884</td>\n",
       "      <td>0.849721</td>\n",
       "      <td>0.854367</td>\n",
       "      <td>2.221606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>734259</td>\n",
       "      <td>0.88640</td>\n",
       "      <td>0.90407</td>\n",
       "      <td>0.88150</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>60.848157</td>\n",
       "      <td>0.873354</td>\n",
       "      <td>0.862690</td>\n",
       "      <td>1.843366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>732880</td>\n",
       "      <td>0.67300</td>\n",
       "      <td>0.67410</td>\n",
       "      <td>0.66780</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>46.142371</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.676583</td>\n",
       "      <td>1.038248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>735211</td>\n",
       "      <td>0.83940</td>\n",
       "      <td>0.84395</td>\n",
       "      <td>0.83500</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>48.905148</td>\n",
       "      <td>0.841863</td>\n",
       "      <td>0.843689</td>\n",
       "      <td>1.377427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>737101</td>\n",
       "      <td>0.87526</td>\n",
       "      <td>0.88381</td>\n",
       "      <td>0.87448</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>44.445886</td>\n",
       "      <td>0.882478</td>\n",
       "      <td>0.884740</td>\n",
       "      <td>1.533204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>733881</td>\n",
       "      <td>0.88200</td>\n",
       "      <td>0.88400</td>\n",
       "      <td>0.86060</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>41.133004</td>\n",
       "      <td>0.886867</td>\n",
       "      <td>0.885899</td>\n",
       "      <td>2.141572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>734896</td>\n",
       "      <td>0.85350</td>\n",
       "      <td>0.87010</td>\n",
       "      <td>0.85290</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>75.820378</td>\n",
       "      <td>0.826718</td>\n",
       "      <td>0.817782</td>\n",
       "      <td>1.372235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>733671</td>\n",
       "      <td>0.90520</td>\n",
       "      <td>0.92980</td>\n",
       "      <td>0.90020</td>\n",
       "      <td>0.9268</td>\n",
       "      <td>66.375566</td>\n",
       "      <td>0.880589</td>\n",
       "      <td>0.869985</td>\n",
       "      <td>2.210994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>731410</td>\n",
       "      <td>0.69290</td>\n",
       "      <td>0.71280</td>\n",
       "      <td>0.69110</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>62.207941</td>\n",
       "      <td>0.698594</td>\n",
       "      <td>0.677968</td>\n",
       "      <td>2.091699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>694 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date     Open     High      Low   Close        rsi  ema_fast  ema_slow  \\\n",
       "746  735645  0.73990  0.74426  0.73400  0.7395  26.837951  0.762767  0.785421   \n",
       "532  734147  0.82953  0.84943  0.82856  0.8426  46.154884  0.849721  0.854367   \n",
       "548  734259  0.88640  0.90407  0.88150  0.8874  60.848157  0.873354  0.862690   \n",
       "352  732880  0.67300  0.67410  0.66780  0.6735  46.142371  0.676357  0.676583   \n",
       "684  735211  0.83940  0.84395  0.83500  0.8426  48.905148  0.841863  0.843689   \n",
       "..      ...      ...      ...      ...     ...        ...       ...       ...   \n",
       "954  737101  0.87526  0.88381  0.87448  0.8758  44.445886  0.882478  0.884740   \n",
       "494  733881  0.88200  0.88400  0.86060  0.8686  41.133004  0.886867  0.885899   \n",
       "639  734896  0.85350  0.87010  0.85290  0.8690  75.820378  0.826718  0.817782   \n",
       "464  733671  0.90520  0.92980  0.90020  0.9268  66.375566  0.880589  0.869985   \n",
       "143  731410  0.69290  0.71280  0.69110  0.7122  62.207941  0.698594  0.677968   \n",
       "\n",
       "     volatility  target  \n",
       "746    1.684036       0  \n",
       "532    2.221606       1  \n",
       "548    1.843366       0  \n",
       "352    1.038248       1  \n",
       "684    1.377427       0  \n",
       "..          ...     ...  \n",
       "954    1.533204       0  \n",
       "494    2.141572       0  \n",
       "639    1.372235       0  \n",
       "464    2.210994       0  \n",
       "143    2.091699       0  \n",
       "\n",
       "[694 rows x 10 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same with scaled data\n",
    "dd_train_scaled = dd_scaled.sample(frac=0.7,random_state=123) \n",
    "dd_val_scaled = dd.drop(dd_train_scaled.index) #should be the same because the random seed is the same than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>rsi</th>\n",
       "      <th>ema_fast</th>\n",
       "      <th>ema_slow</th>\n",
       "      <th>volatility</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>735645</td>\n",
       "      <td>-0.344226</td>\n",
       "      <td>-0.347213</td>\n",
       "      <td>-0.342191</td>\n",
       "      <td>-0.352639</td>\n",
       "      <td>-2.395082</td>\n",
       "      <td>-0.091943</td>\n",
       "      <td>0.189489</td>\n",
       "      <td>-0.302474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>734147</td>\n",
       "      <td>0.590224</td>\n",
       "      <td>0.631551</td>\n",
       "      <td>0.658073</td>\n",
       "      <td>0.722945</td>\n",
       "      <td>-0.512833</td>\n",
       "      <td>0.822279</td>\n",
       "      <td>0.927130</td>\n",
       "      <td>0.060630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>734259</td>\n",
       "      <td>1.183129</td>\n",
       "      <td>1.140057</td>\n",
       "      <td>1.218078</td>\n",
       "      <td>1.190317</td>\n",
       "      <td>0.918885</td>\n",
       "      <td>1.070758</td>\n",
       "      <td>1.016178</td>\n",
       "      <td>-0.194854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>732880</td>\n",
       "      <td>-1.041700</td>\n",
       "      <td>-1.000156</td>\n",
       "      <td>-1.042461</td>\n",
       "      <td>-1.041179</td>\n",
       "      <td>-0.514052</td>\n",
       "      <td>-1.000451</td>\n",
       "      <td>-0.974944</td>\n",
       "      <td>-0.738674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>735211</td>\n",
       "      <td>0.693125</td>\n",
       "      <td>0.580551</td>\n",
       "      <td>0.726196</td>\n",
       "      <td>0.722945</td>\n",
       "      <td>-0.244846</td>\n",
       "      <td>0.739657</td>\n",
       "      <td>0.812889</td>\n",
       "      <td>-0.509574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>737101</td>\n",
       "      <td>1.066988</td>\n",
       "      <td>0.951508</td>\n",
       "      <td>1.143820</td>\n",
       "      <td>1.069301</td>\n",
       "      <td>-0.679358</td>\n",
       "      <td>1.166688</td>\n",
       "      <td>1.252085</td>\n",
       "      <td>-0.404354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>733881</td>\n",
       "      <td>1.137257</td>\n",
       "      <td>0.953276</td>\n",
       "      <td>0.996996</td>\n",
       "      <td>0.994188</td>\n",
       "      <td>-1.002167</td>\n",
       "      <td>1.212827</td>\n",
       "      <td>1.264486</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>734896</td>\n",
       "      <td>0.840126</td>\n",
       "      <td>0.823916</td>\n",
       "      <td>0.915544</td>\n",
       "      <td>0.998361</td>\n",
       "      <td>2.377784</td>\n",
       "      <td>0.580426</td>\n",
       "      <td>0.535713</td>\n",
       "      <td>-0.513081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>733671</td>\n",
       "      <td>1.379131</td>\n",
       "      <td>1.379513</td>\n",
       "      <td>1.415888</td>\n",
       "      <td>1.601355</td>\n",
       "      <td>1.457478</td>\n",
       "      <td>1.146821</td>\n",
       "      <td>1.094226</td>\n",
       "      <td>0.053462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>731410</td>\n",
       "      <td>-0.834230</td>\n",
       "      <td>-0.639995</td>\n",
       "      <td>-0.795991</td>\n",
       "      <td>-0.637444</td>\n",
       "      <td>1.051383</td>\n",
       "      <td>-0.766655</td>\n",
       "      <td>-0.960124</td>\n",
       "      <td>-0.027117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>694 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Open      High       Low     Close       rsi  ema_fast  \\\n",
       "746  735645 -0.344226 -0.347213 -0.342191 -0.352639 -2.395082 -0.091943   \n",
       "532  734147  0.590224  0.631551  0.658073  0.722945 -0.512833  0.822279   \n",
       "548  734259  1.183129  1.140057  1.218078  1.190317  0.918885  1.070758   \n",
       "352  732880 -1.041700 -1.000156 -1.042461 -1.041179 -0.514052 -1.000451   \n",
       "684  735211  0.693125  0.580551  0.726196  0.722945 -0.244846  0.739657   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "954  737101  1.066988  0.951508  1.143820  1.069301 -0.679358  1.166688   \n",
       "494  733881  1.137257  0.953276  0.996996  0.994188 -1.002167  1.212827   \n",
       "639  734896  0.840126  0.823916  0.915544  0.998361  2.377784  0.580426   \n",
       "464  733671  1.379131  1.379513  1.415888  1.601355  1.457478  1.146821   \n",
       "143  731410 -0.834230 -0.639995 -0.795991 -0.637444  1.051383 -0.766655   \n",
       "\n",
       "     ema_slow  volatility  target  \n",
       "746  0.189489   -0.302474       0  \n",
       "532  0.927130    0.060630       1  \n",
       "548  1.016178   -0.194854       0  \n",
       "352 -0.974944   -0.738674       1  \n",
       "684  0.812889   -0.509574       0  \n",
       "..        ...         ...     ...  \n",
       "954  1.252085   -0.404354       0  \n",
       "494  1.264486    0.006570       0  \n",
       "639  0.535713   -0.513081       0  \n",
       "464  1.094226    0.053462       0  \n",
       "143 -0.960124   -0.027117       0  \n",
       "\n",
       "[694 rows x 10 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM: The sampling doesn't respect the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model function. \n",
    "The following function trains a model (defined by the model_name variable and the choosen parameters) and returns the results in terms of accuracy, sensitivity, sensibility and score (0.6 x sensitivity + 0.4 x specificity).\n",
    "It uses 10 cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def model_function_completed(dd, model_name, balancing = \"none\", sampling =\"standard\",\n",
    "                             LDA_priors = None, LDA_shrinkage=None, LDA_solver='svd',\n",
    "                             QDA_priors = None, QDA_reg_param = -1,\n",
    "                             SVM_kernel = 'duh', SVM_C = -1, SVM_CW = None, SVM_Gamma = \"scale\", SVM_Degree=3, SVM_Coef0=0.0, SVM_shrinking = False):\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "    \n",
    "    accuracy = 0\n",
    "    sensitivity = 0\n",
    "    specificity = 0\n",
    "    score = 0\n",
    "\n",
    "    #10 CV\n",
    "    for j in range(10):\n",
    "        n_cols = dd.shape[1]\n",
    "        y = dd.iloc[:,n_cols-1:n_cols]\n",
    "        \n",
    "        #SAMPLING METHOD\n",
    "        if (sampling == \"standard\"):\n",
    "            train = dd.sample(frac=0.7,random_state=200+j) #random state is a seed value\n",
    "            test = dd.drop(train.index)\n",
    "            n_cols = dd.shape[1]\n",
    "            x_train = train.iloc[:,:n_cols-1]\n",
    "            y_train = train.iloc[:,n_cols-1:n_cols]\n",
    "            x_test = test.iloc[:,:n_cols-1]\n",
    "            y_test = test.iloc[:,n_cols-1:n_cols]\n",
    "      \n",
    "        elif (sampling == \"balanced_resampling\"):\n",
    "            n_cols = dd.shape[1]\n",
    "            x_train, x_test, y_train, y_test = train_test_split(dd.iloc[:,:n_cols-1],dd.iloc[:,n_cols-1:n_cols], test_size=0.3, random_state=123+j)\n",
    "\n",
    "        #for each target\n",
    "        for i in range(1):\n",
    "\n",
    "            #BALANCING METHOD\n",
    "            #oversample\n",
    "            if (balancing == 'oversample'):\n",
    "                x_train_balanced, y_train_balanced = oversample.fit_resample(x_train, y_train)\n",
    "            #undersample\n",
    "            elif (balancing == 'undersample'):\n",
    "                x_train_balanced, y_train_balanced = undersample.fit_resample(x_train, y_train)\n",
    "            #none\n",
    "            elif (balancing == 'none'):\n",
    "                x_train_balanced = x_train\n",
    "                y_train_balanced = y_train\n",
    "\n",
    "            #MODEL NAME\n",
    "            if (model_name == \"LDA\"):\n",
    "                if (LDA_solver == 'svd'):\n",
    "                    #shrinkage is not supported for svd solver\n",
    "                    mod = LinearDiscriminantAnalysis(priors = LDA_priors, solver = LDA_solver)   \n",
    "                else:\n",
    "                    mod = LinearDiscriminantAnalysis(priors = LDA_priors, shrinkage = LDA_shrinkage, solver = LDA_solver)\n",
    "                \n",
    "            elif (model_name == \"QDA\"):\n",
    "                mod = QuadraticDiscriminantAnalysis(priors = QDA_priors, reg_param = QDA_reg_param)\n",
    "        \n",
    "            elif (model_name == \"SVM\"):\n",
    "                mod = SVC(kernel=SVM_kernel, max_iter = 200, C = SVM_C, class_weight = SVM_CW, gamma = SVM_Gamma, degree = SVM_Degree, coef0 = SVM_Coef0, shrinking = SVM_shrinking)\n",
    "            \n",
    "            mod.fit(x_train_balanced, y_train_balanced)\n",
    "            test_prediction = mod.predict(x_test)\n",
    "            cm = confusion_matrix(y_test, test_prediction)\n",
    "        \n",
    "            sensitivity +=  (cm[1,1]/(cm[1,1]+cm[1,0]))/10\n",
    "            specificity +=  (cm[0,0]/(cm[0,0]+cm[0,1]))/10\n",
    "            accuracy += mod.score(x_test, y_test)/10\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "    score = 0.6*sensitivity + 0.4*specificity\n",
    "    \"\"\"results[i][0] = accuracy[i]\n",
    "    results[i][1] = sensitivity[i]\n",
    "    results[i][2] = specificity\"\"\"\n",
    "    \n",
    "    results = [accuracy,sensitivity,specificity,score]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59  85]\n",
      " [ 52 102]]\n",
      "0.6623376623376623 0.4097222222222222 0.540268456375839\n"
     ]
    }
   ],
   "source": [
    "# LDA BASELINE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#particion test y train, x e y\n",
    "n_cols = dd.shape[1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(dd.iloc[:,:n_cols-1],dd.iloc[:,n_cols-1:n_cols], test_size=0.3, random_state=123)\n",
    "\n",
    "#modelo\n",
    "mod = LinearDiscriminantAnalysis()\n",
    "mod.fit(x_train, y_train)\n",
    "test_prediction = mod.predict(x_test)\n",
    "cm = confusion_matrix(y_test, test_prediction) \n",
    "print(cm)\n",
    "\n",
    "\n",
    "sensitivity =  (cm[1,1]/(cm[1,1]+cm[1,0]))\n",
    "specificity =  (cm[0,0]/(cm[0,0]+cm[0,1]))\n",
    "accuracy = mod.score(x_test, y_test)\n",
    "print(sensitivity, specificity, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### USING THE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the following balancing method: none\n",
      "[0.6324356313524198, ['lsqr', 'auto', 0.4, 'standard'], [0.5649038461538463, 0.9223293898370044, 0.19759499362554275]]\n"
     ]
    }
   ],
   "source": [
    "prints = True\n",
    "#First hyperparameter: balancing method\n",
    "for method in ['none']: #undersample has the best performance for LDA  --- , 'oversample', 'undersample']\n",
    "    if (prints): \n",
    "        print(\"With the following balancing method:\", method)\n",
    "    #Hyperparameter optimitzation:\n",
    "    #Best score, best hyperparameters, other performance measurements\n",
    "    max = [0,0,0]\n",
    "    \n",
    "    #Hyperparameter values\n",
    "    solver = ['svd', 'lsqr', 'eigen']\n",
    "    shrinkage = ['auto']#, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 0.9]\n",
    "    sampling = [\"standard\"] #\"balanced_resampling\", \n",
    "    \n",
    "    #Second hyperparameter: solver (solv)\n",
    "    for solv in solver:\n",
    "        #Third hyperparameter: shrinkage (s)\n",
    "        for s in shrinkage:\n",
    "            #Fourth hyperparameter: priors (p)\n",
    "            for p in range (1,20): \n",
    "                prior =  [0.05*p,1-p*0.05]\n",
    "                #Fifth hyperparameter: sampling method (sa)\n",
    "                for sa in sampling:\n",
    "                    #Training the model with all hyperparameter combinations\n",
    "                    results = model_function_completed(dd_train, \"LDA\", LDA_priors = prior, balancing = method, sampling = sa, LDA_shrinkage = s, LDA_solver = solv)\n",
    "                    #Select the hyperparameters that maximize the performance of the model for each targe\n",
    "                    if (max[0] < results[3]): #Comparison based in score\n",
    "                        max[0] = results[3] #Maximum score\n",
    "                        max[1] = [solv, s, prior[0], sa] #Best solv, s, prior, sa based in score\n",
    "                        max[2] = [results[0], results[1], results[2]] #Accuracy, sensitivy, specificity\n",
    "                                  \n",
    "    print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the following balancing method: none\n",
      "[0.626477733075052, ['scaled', 0.75, 0.35000000000000003, 'balanced_resampling'], [0.554066985645933, 0.8896062541986948, 0.23178495138958796]]\n"
     ]
    }
   ],
   "source": [
    "prints = True\n",
    "#First hyperparameter: balancing method\n",
    "for method in ['none']: #undersample has the best performance for LDA  --- , 'oversample', 'undersample']\n",
    "    if (prints): \n",
    "        print(\"With the following balancing method:\", method)\n",
    "    #Hyperparameter optimitzation:\n",
    "    #Best score, best hyperparameters, other performance measurements\n",
    "    max = [0,0,0]\n",
    "    \n",
    "    #Hyperparameter values\n",
    "    data = ['original', 'scaled']\n",
    "    sampling = [\"balanced_resampling\", \"standard\"] #\"balanced_resampling\", \n",
    "    \n",
    "\n",
    "    #Second hyperparameter: data (d)\n",
    "    for d in data:\n",
    "        #Third hyperparameter: regularization parameter (rp)\n",
    "        for rp in range (0,20): \n",
    "            reg_param = 0.05*rp\n",
    "            #Fourth hyperparameter: priors (p)\n",
    "            for p in range (1,20): \n",
    "                prior =  [0.05*p,1-p*0.05]\n",
    "                #Fifth hyperparameter: sampling method (sa)\n",
    "                for sa in sampling:\n",
    "                    #Training the model with all hyperparameter combinations\n",
    "                    if (d == 'original'):\n",
    "                        results = model_function_completed(dd_train, \"QDA\", balancing = method, sampling = sa, QDA_priors = prior, QDA_reg_param = reg_param)\n",
    "                    elif (d == 'scaled'):\n",
    "                        results = model_function_completed(dd_train_scaled, \"QDA\", balancing = method, sampling = sa, QDA_priors = prior, QDA_reg_param = reg_param)\n",
    "                        #Select the hyperparameters that maximize the performance of the model\n",
    "                        if (max[0] < results[3]): #Comparison based in score\n",
    "                            max[0] = results[3] #Maximum score\n",
    "                            max[1] = [d, reg_param, prior[0], sa] #Best solv, s, prior, sa based in score\n",
    "                            max[2] = [results[0], results[1], results[2]] #Accuracy, sensitivy, specificity\n",
    "                            \n",
    "    print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the following balancing method: none\n",
      "[0.5999999999999999, ['scaled', 0.9500000000000001, 0.9500000000000001, 'standard'], [0.4899521531100478, 0.9999999999999999, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "kernel = 'sigmoid'\n",
    "prints = True\n",
    "#First hyperparameter: balancing method\n",
    "for method in ['none']:\n",
    "    if (prints): \n",
    "        print(\"With the following balancing method:\", method)\n",
    "    #Hyperparameter optimitzation:\n",
    "    #Best score, best hyperparameters, other performance measurements\n",
    "    max = [0,0,0]\n",
    "  \n",
    "    #Hyperparameter values\n",
    "    gamma =  ['scale', 0.5, 1, 2, 5, 7, 10]\n",
    "    c_values = [1, 3, 5, 10, 20, 50, 75, 100]\n",
    "    cw_values = [\"balanced\", None]\n",
    "    shrinking = [True, False]\n",
    "  \n",
    "    #Second hyperparameter: cost (c)\n",
    "    for c in c_values: \n",
    "        #Third hyperparameter: class weight (cw)\n",
    "        for cw in cw_values:\n",
    "            #Fourth hyperparameter: shrinking (s)\n",
    "            for s in shrinking:\n",
    "                #Fifth hyperparameter: gamma (g)\n",
    "                for g in gamma:\n",
    "                    #Training the model with all hyperparameter combinations\n",
    "                    results = model_function_completed(dd_train_scaled, \"SVM\", SVM_kernel=kernel, balancing = method, sampling = \"balanced_resampling\", SVM_C = c, SVM_CW = cw, SVM_shrinking = s, SVM_Gamma = g)\n",
    "                    #Select the hyperparameters that maximize the performance of the model\n",
    "                    if (max[0] < results[3]): #Comparison based in score\n",
    "                            max[0] = results[3] #Maximum score\n",
    "                            max[1] = [d, reg_param, prior[0], sa] #Best solv, s, prior, sa based in score\n",
    "                            max[2] = [results[0], results[1], results[2]] #Accuracy, sensitivy, specificity\n",
    "\n",
    "    print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM RBF: Has overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### POLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the following balancing method: none\n",
      "[0.5999999999999999, ['scaled', 0.9500000000000001, 0.9500000000000001, 'standard'], [0.4899521531100478, 0.9999999999999999, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "kernel = 'poly'\n",
    "prints = True\n",
    "#First hyperparameter: balancing method\n",
    "for method in ['none']:\n",
    "    if (prints): \n",
    "        print(\"With the following balancing method:\", method)\n",
    "    #Hyperparameter optimitzation:\n",
    "    #Best score, best hyperparameters, other performance measurements\n",
    "    max = [0,0,0]\n",
    "  \n",
    "    #Hyperparameter values\n",
    "    gamma =  ['scale', 0.5, 1, 2, 5, 7, 10]\n",
    "    c_values = [1, 3, 5, 10, 20, 50, 75, 100]\n",
    "    cw_values = [\"balanced\", None]\n",
    "    shrinking = [True, False]\n",
    "  \n",
    "    #Second hyperparameter: cost (c)\n",
    "    for c in c_values: \n",
    "        #Third hyperparameter: class weight (cw)\n",
    "        for cw in cw_values:\n",
    "            #Fourth hyperparameter: shrinking (s)\n",
    "            for s in shrinking:\n",
    "                #Fifth hyperparameter: gamma (g)\n",
    "                for g in gamma:\n",
    "                    #Training the model with all hyperparameter combinations\n",
    "                    results = model_function_completed(dd_train_scaled, \"SVM\", SVM_kernel=kernel, balancing = method, sampling = \"balanced_resampling\", SVM_C = c, SVM_CW = cw, SVM_shrinking = s, SVM_Gamma = g)\n",
    "                    #Select the hyperparameters that maximize the performance of the model\n",
    "                    if (max[0] < results[3]): #Comparison based in score\n",
    "                            max[0] = results[3] #Maximum score\n",
    "                            max[1] = [d, reg_param, prior[0], sa] #Best solv, s, prior, sa based in score\n",
    "                            max[2] = [results[0], results[1], results[2]] #Accuracy, sensitivy, specificity\n",
    "\n",
    "    print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSIONS\n",
    "Based on the results, we conclude that the LDA, QDA and SVM models do not have sufficient predictive power over the data. The accuracy is slightly over 50%, so it does not offer a significant improvement over a random prediction. With this in mind, we discard these models and do not proceed to evaluate them with the validation data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
